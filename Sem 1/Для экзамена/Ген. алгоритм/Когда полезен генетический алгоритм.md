1. Иногда мы не можем нормально построить [[Порядок ответа градиентный спуск|градиент]] и соответственно воспользоваться градиентным спуском. (есть и другие [[Список неградиентных методов оптимизации|неградиентные методы]]). 
2. Когда мы делаем [[Многопараметрическая оптимизация. Доминантность и оптимальность по Парето.|многопараметрическую оптимизацию]] - функция возвращает сразу несколько значений, которые мы хотим оптимизировать (Нужно добрать от дома до кампуса минимизируя деньги и время, но если мы хотим добраться быстрее обычно платим больше) Это можно делать и когда 

Чем отличается именно генетический от всех остальных неградиентных методов? - Ну, он достаточно гибкий. Мы можем подойти к нему творчески и выбирать реализацию селекции, кроссовера, мутации, которые мы хотим и в целом конструировать так, как сами считаем нужным.

Минус старения в генетическом алгоритме - на последней итерации может убить лучшую особь, поэтому надо их отдельно сохранять
