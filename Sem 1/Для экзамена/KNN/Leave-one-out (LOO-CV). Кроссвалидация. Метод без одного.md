#кроссвалидация #LOO-CV #Переобучение #k-fold
#### **Кросс-валидация (Cross-Validation)**

Кросс-валидация — это метод оценки качества модели, который помогает определить её обобщающую способность на **неизвестных данных**.

Основная идея: **разделить данные на обучающую и тестовую выборки несколько раз** и усреднить результаты.

Она может применяться для оценки любой количественной метрики качества модели, подходящей для конкретных данных.

- **Для задач бинарной классификации** можно использовать уровень ошибок классификации или метрики, основанные на данных из матрицы ошибок (confusion matrix).

- **Для задач регрессии**, где предсказываемое значение является непрерывным, используются метрики такие как:
    - Среднеквадратичная ошибка (Mean Squared Error, MSE)
    - Корень из среднеквадратичной ошибки (Root Mean Squared Error, RMSE)
    - Медианное абсолютное отклонение (Median Absolute Deviation, MAD)

##### **Зачем нужна кросс-валидация?**

1. **Оценка обобщающей способности модели:** Кросс-валидация предоставляет более точную оценку модели, чем **однократное разбиение** данных на обучающую и тестовую выборки. Это важно, потому что одно случайное разбиение может привести к **перетренированию** (overfitting) или наоборот, недостаточному обучению модели.
    
2. **Борьба с переобучением (Overfitting):** Модели могут «запомнить» данные и показывать отличные результаты на обучающей выборке, но плохо работать на новых данных. Кросс-валидация помогает избежать такого поведения, оценивая модель на **нескольких тестовых наборах**, которые не пересекаются с обучающими.
    
3. **Объективная оценка модели:** Используя кросс-валидацию, мы получаем **среднюю оценку** модели, которая является более стабильной и объективной, чем оценка по одному набору данных. Это снижает влияние случайных факторов (например, случайное разбиение на тестовую и обучающую выборки).
    
4. **Использование всех данных:** В процессе кросс-валидации каждая запись из исходных данных будет использована и для обучения, и для тестирования, что позволяет использовать **максимальное количество данных** для обучения и тестирования.

##### **Как работает кросс-валидация?**

1. **Разбиение данных**:  
    Данные делятся на несколько частей или **фолдов**. Количество фолдов зависит от типа кросс-валидации (например, 5-Fold, 10-Fold).
    
2. **Обучение и тестирование**:  
    Для каждого фолда:
    
    - Модель обучается на данных из **k−1 фолдов.
    - Оценка производится на данных **из оставшегося фолда**, который в данном цикле используется как тестовый.
    
3. **Повторение**:  
    Этот процесс повторяется столько раз, сколько фолдов в разбиении, и каждый объект данных будет использован как тестовый **ровно один раз**.
    
4. **Средняя оценка**:  
    После выполнения всех циклов вычисляется **средняя точность** (или другая метрика) модели по всем фолдам.


##### **Цель и задачи кросс-валидации**

**Цель**:  
Основная цель кросс-валидации — **получить объективную и стабильную оценку качества модели**, которая будет отражать её способность работать на новых, ранее не встречавшихся данных.

**Задачи кросс-валидации:**

1. **Предотвращение переобучения (overfitting)**:  
    Кросс-валидация помогает убедиться, что модель не подгоняется под особенности обучающих данных (например, случайные шумы).
    
2. **Выбор модели и гиперпараметров**:  
    В процессе подбора модели (например, выбор между линейной регрессией, деревом решений или SVM) и настроек (например, значения гиперпараметра CCC в SVM) кросс-валидация позволяет выбрать наилучшую модель.
    
3. **Достижение обоснованной уверенности**:  
    Когда мы получаем среднюю точность модели по всем фолдам, мы имеем уверенность в её стабильности и способности работать на разных поднаборах данных.
    
4. **Тестирование на реальных данных**:  
    Кросс-валидация помогает протестировать модель на различных случайных подмножествах данных, что даёт более точную картину её работы на реальных данных.\


#### **k-Fold**

![[Pasted image 20250201184614.png]]

![[Pasted image 20250201184633.png]]

Преимущества k-Fold

- **Объективность**: Модель тестируется на каждом объекте данных.
- **Надёжность**: Средняя оценка по всем фолдам дает более стабильную оценку качества модели.
- **Использование всех данных**: Каждый объект будет использоваться как тестовый хотя бы один раз, что даёт модели больше возможностей для обучения.

Недостатки k-Fold

- Может быть **медленным**, если k слишком большое.
- Если **данные сильно несбалансированы**, может потребоваться использование **Stratified k-Fold** для более равномерного распределения классов.
#### **LOO-CV (Тоже самое, что и k-Fold, просто k = n)**

LOO-CV — это частный случай k-Fold, когда k=n , где n — это количество объектов в выборке. В этом методе **каждый объект** используется как **тестовый** ровно один раз, а все остальные n−1 объектов используются для обучения модели. Этот процесс повторяется **для каждого объекта** в данных, и итоговая оценка модели основывается на усреднении результатов всех тестов.

##### Как работает LOO-CV?

1. **Шаг 1**: Каждый объект из выборки по очереди используется как тест.
    
    - Например, если у вас 100 объектов, то на первом шаге объект 1 будет тестом, и модель будет обучаться на 99 объектах. На втором шаге объект 2 будет тестом, и модель будет обучаться на остальных 99 объектах.
    - 
2. **Шаг 2**: Повторите для каждого объекта.
    
    - Для n объектов это даст n итераций обучения и тестирования.
3. **Шаг 3**: Усредните все полученные результаты.
    
    - Если, например, вы используете точность как метрику, то после n-периодов тестирования вы получите n значений точности, которые нужно усреднить.

![[Pasted image 20250201184450.png]]


![[Pasted image 20250201184439.png]]

#### **Вывод**

- **k-Fold** — это универсальный метод, подходящий для большинства задач, особенно если данных много. Он сбалансирован по времени выполнения и точности.
- **LOO-CV** — это метод с самой высокой точностью, но он может быть крайне медленным на больших данных. Подходит для малых выборок, где каждый объект важен для оценки модели.

Выбор между этими методами зависит от **размера данных** и **необходимой точности**.