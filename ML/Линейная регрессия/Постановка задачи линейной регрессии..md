Линейная регрессия — это метод машинного обучения, который используется для предсказания числового значения целевой переменной y на основе одной или нескольких входных переменных x.

**Восстановить зависимость одной переменной Y от другой или нескольких других переменных X с линейной функцией зависимости (переменные количественные).**

Линейная регрессия — это метод предсказания числового значения на основе нескольких входных факторов. Она позволяет найти закономерность между зависимой переменной (то, что нужно предсказать) и независимыми переменными (факторы, влияющие на результат).

**Пример формулировки:**  
«Необходимо спрогнозировать стоимость квартиры на основе её характеристик, таких как площадь, количество комнат и этаж. Для этого используется модель линейной регрессии, которая строит зависимость между ценой квартиры и заданными параметрами. Цель — подобрать такие коэффициенты модели, чтобы разница между предсказанными и фактическими ценами была минимальной.»

Если нужно формально:  
«Дана выборка данных, содержащая m наблюдений, где для каждого объекта известен набор признаков и целевое значение. Требуется построить модель линейной регрессии, которая аппроксимирует зависимость целевой переменной y от набора признаков X, минимизируя среднеквадратичную ошибку.»

Главное — чётко обозначить цель: предсказать числовую переменную на основе других факторов.

![[Pasted image 20250205145913.png]]

![[Pasted image 20250205145939.png]]


![[Pasted image 20250205145949.png]]

![[Pasted image 20250415005847.png]]
X - матрица где m строк и n+1 столбец
y - вектор длины m
тета - вектор длины n + 1 - веса признаков

Важная штука $$ \displaylines{ (AB)^{T}= B^{T}A^{T} \\
(ABC)^{T} = C^{T} B^{T} A^{T}
}$$
$$\displaylines{
||y- \hat {y}|| ^ {2} =  \\
= (y-x\cdot \theta)^{T}(y - x\cdot\theta) = 

y^{T} y - y^{T}\cdot
x\theta - \theta^{T}x^{T}y + \theta^{T} x^{T} x \theta \\ \\

y^{T} y \text{ - это число}\\\\
~~~~~~~~~~~~(m,) (m,n+1)(n+1) ~ \text{ размерности}\\
y^{T} ~~~~\cdot ~~~~~~x ~~~~~~~~~\theta \rightarrow  \text{число} \\\\

~~~~~~~~~~~~(1,n+1) (n+1,m)(m) ~ \text{ размерности}\\
~~~~~~\theta ^ {T} ~~~~~~~~~~~~x^{T} ~~~~~~~~~~~~ y \rightarrow  \text{число} \\\\

~~~~~~~~~~~~(1,n+1) (n+1,m)(m, n+1)(n+1) ~ \text{ размерности}\\
~~~~\theta^{T} ~~~~~~~~~~~ x^{T}~~~~~~~~~~~~~~~~ ~~ x ~~~~~~~~~~~\theta \rightarrow  \text{число} \\\\

\text{A ещё } ~ \theta^{T}x^{T}y = y^{T}\cdot
x\theta \\ 
\text {Потому что  } ~ (\theta^{T}x^{T}y)^T = y^{T}\cdot
x\theta \\ 
\text{ А так как и то, и то число, то они как бы равны} \\\\

\text{Следовательно получаем, что } 
||y- \hat {y}|| ^ {2} =  \\
= (y-x\cdot \theta)^{T}(y - x\cdot\theta) = 

y^{T} y - y^{T}\cdot x\theta - \theta^{T}x^{T}y + \theta^{T} x^{T} x \theta = \\
= y^{T} y - 2 y^{T}\cdot x\theta + \theta^{T} x^{T} x \theta \\\\


%% терепь производная

\text{А теперь берём производную по тета:} \\

(y^{T}y)^{'}_{\theta} = 0 \text{ Т.к. тета здесь нет } \\
(2 y^{T}\cdot x\theta)^{'}_{\theta} = 2 y^{T}\cdot x \\
(\theta^{T} x^{T} x \theta)^{'}_{\theta} = 2 x^{T} x \theta  \\ \text{  А хрен его знает почему пропала тета транспонированая и почему появилась двойка} \\\\

\text{Тогда производная по тета от всей функции равна} \\
(||y- \hat {y}|| ^ {2})^{'}_{\theta} = \left( (y-x\cdot \theta)^{T}(y - x\cdot\theta) \right)^{'}_{\theta} = - 2 y^{T} \cdot x + 2 x^{T} x \theta \\\\

\text{Приравняем проихводную к нулю, чтобы найти точку экстремума:}\\
 - 2 y^{T} \cdot x + 2 x^{T} x \theta = 0 \\\\

\text{Перенесём часть с минусом вправо и поделим на 2, потому что это чилсо, получим:} \\
 x^{T} x \theta =  y^{T} \cdot x

}$$
Ещё одна важная штука 
$$\displaylines{ I = X^{-1}\cdot X = X\cdot X^{-1}}$$
Вернёмся к уравнению, мы хотим получить в левой части тета, для этого нужно домножить обе части слева на 
$$\displaylines{ (x^{T}x)^{-1} ~~~ \text{Получим:}\\
(x^{T}x)^{-1} \cdot x^{T} x \theta =  (x^{T}x)^{-1} \cdot y^{T} \cdot x \\\text{В результате в левой части иксы сокращаются, становясь единичной матрицей, итог:}\\
\theta =  (x^{T}x)^{-1} \cdot y^{T} \cdot x
}$$

Как понять, что эта точка действительно минимум?

Если вторая производная положительно опредена, то это действительно минимум. (Если посчитаем производную, то действитльно узнаем, что она положительна опрпеделена).

Проблемы этого решения: 
- нахождения обратной матрицы это очень долго
- обратной матрицы может не быть (т.к. строчки или столбцы матрицы могут быть слишком одинаковыми/линейнозависимыми (мультиколлинеарность) -> определитель равен нулю)

Её очень любит сбербанк, потому что у неё очень хорошая объяснимость.